{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataFileHandler import *\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 0\n",
    "test_dict = {}\n",
    "while x < 2:\n",
    "    test_dict[x] = {}\n",
    "    x = x +1\n",
    "\n",
    "test_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"C:/Users/Purkinje/Box/NeuroRoboticsLab/NERVES Lab/Project Groups/ML Gait/Experimental Data/TestJan8\"\n",
    "filename = 'Trial 1.h5'\n",
    "\n",
    "completeFilePath = os.path.join(filepath, filename)\n",
    "if not os.path.exists(filepath):\n",
    "    os.makedirs(filepath)\n",
    "\n",
    "hdf5File = h5py.File(completeFilePath, 'a')\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Attributes of HDF5 object at 1876130559296>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5File['Foot 0'].attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5File.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groups, datasets, data\n",
    "testDictDelsys = {'Sensor 1' : {'Channels' : ['EMG', 'GYRO'], 'SampleRates' : [2, 3], 'Attachment' : 'Bicep'},\n",
    "            'Sensor 2' : {'Channels' : ['EKG', 'GYRO'], 'SampleRates' : [3, 6], 'Attachment' : 'Tricep'}}\n",
    "\n",
    "testDictXSensor = {'Foot 1' : {'Channels' : ['EMG'], 'SampleRates' : [2], 'Foot' : ['Right']},\n",
    "            'Foot 2' : {'Channels' : ['EKG'], 'SampleRates' : [3], 'Foot' : ['Left']}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in testDictDelsys.items():\n",
    "    print(key)\n",
    "    for i in range(len(value['Channels'])):\n",
    "        print(value['Channels'][i])\n",
    "        print(value['SampleRates'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDictDelsys.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFileHandler = DataFileHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFileHandler.createFile('TestingFormat7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor 1 {'Channels': ['EMG', 'GYRO'], 'SampleRates': [2, 3], 'Attachment': 'Bicep'}\n",
      "EMG\n",
      "GYRO\n",
      "Sensor 2 {'Channels': ['EKG', 'GYRO'], 'SampleRates': [3, 6], 'Attachment': 'Tricep'}\n",
      "EKG\n",
      "GYRO\n",
      "Foot 1 {'Channels': ['EMG'], 'SampleRates': [2], 'Foot': ['Right']}\n",
      "EMG\n",
      "Foot 2 {'Channels': ['EKG'], 'SampleRates': [3], 'Foot': ['Left']}\n",
      "EKG\n"
     ]
    }
   ],
   "source": [
    "# Formatting File\n",
    "DataFileHandler.formatFile(testDictDelsys, testDictXSensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('TestingFormat2.h5', 'a') as hf:\n",
    "    print(hf.keys())\n",
    "    print(hf['Sensor 1/EMG'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFileHandler.hdf5File['Sensor 1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding data to datasets\n",
    "# Example Data\n",
    "testData = [[1, 2, 3, 4], \n",
    "            [0, 0, 1, 1],\n",
    "            [1, 2, 3, 4],\n",
    "            [0, 0, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sensor 1': {'Channels': ['EMG', 'GYRO'], 'SampleRates': [2, 3], 'Attachment': 'Bicep'}, 'Sensor 2': {'Channels': ['EKG', 'GYRO'], 'SampleRates': [3, 6], 'Attachment': 'Tricep'}}\n",
      "Error getting dataset\n",
      "Error getting shape\n",
      "Error resizing\n",
      "Error adding new data\n",
      "Error getting dataset\n",
      "Error getting shape\n",
      "Error resizing\n",
      "Error adding new data\n",
      "Error getting dataset\n",
      "Error getting shape\n",
      "Error resizing\n",
      "Error adding new data\n",
      "Error getting dataset\n",
      "Error getting shape\n",
      "Error resizing\n",
      "Error adding new data\n"
     ]
    }
   ],
   "source": [
    "# Saving Data to Delsys\n",
    "DataFileHandler.saveDelsysData(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['Foot 1', 'Foot 2', 'Sensor 1', 'Sensor 2']>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFileHandler.hdf5File.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"EMG\": shape (4,), type \"<f4\">"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFileHandler.hdf5File['Sensor 1']['EMG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFileHandler.closeFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataFileHandler.hdf5File['Sensor 1/EMG']  # Access 'dataset1' in 'group1'\n",
    "\n",
    "# Read existing data from the dataset\n",
    "existing_data = dataset[:]\n",
    "print(existing_data)\n",
    "\n",
    "# Generate new data to add\n",
    "new_data = np.array([10, 20, 30])\n",
    "\n",
    "# Concatenate existing data with new data\n",
    "updated_data = np.concatenate((existing_data, new_data))\n",
    "print(updated_data)\n",
    "existing_data = updated_data\n",
    "print(existing_data)\n",
    "\n",
    "dataset[...] = existing_data\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the HDF5 file in read/write mode\n",
    "with h5py.File('TestingFormat0.h5', 'a') as hf:\n",
    "    # Access the specific dataset\n",
    "    dataset = hf['Sensor 1/EMG']  # Access 'dataset1' in 'group1'\n",
    "\n",
    "    # Generate new data to replace the existing dataset\n",
    "    new_data = np.array([100, 200, 300])\n",
    "\n",
    "    # Assign new values to the dataset\n",
    "    dataset[...] = new_data\n",
    "\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Create or open an HDF5 file in write mode\n",
    "with h5py.File('multilevel.h5', 'w') as hf:\n",
    "    # Create subgroup 'group1' under the root group '/'\n",
    "    group1 = hf.create_group('group1')\n",
    "\n",
    "    # Create datasets within 'group1'\n",
    "    data1 = np.array([1, 2, 3])\n",
    "    group1.create_dataset('dataset1', data=data1)\n",
    "\n",
    "    data2 = np.array([4, 5, 6])\n",
    "    group1.create_dataset('dataset2', data=data2)\n",
    "\n",
    "    # Create subgroup 'group2' under the root group '/'\n",
    "    group2 = hf.create_group('group2')\n",
    "\n",
    "    # Create datasets within 'group2'\n",
    "    data3 = np.array([7, 8, 9])\n",
    "    group2.create_dataset('dataset3', data=data3)\n",
    "\n",
    "    data4 = np.array([10, 11, 12])\n",
    "    group2.create_dataset('dataset4', data=data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Open the HDF5 file in read/write mode\n",
    "with h5py.File('multilevel.h5', 'a') as hf:\n",
    "    # Access the specific dataset\n",
    "    dataset = hf['group1/dataset1']  # Access 'dataset1' in 'group1'\n",
    "\n",
    "    # Generate new data to replace the existing dataset\n",
    "    new_data = np.array([100, 200, 300])\n",
    "\n",
    "    # Assign new values to the dataset\n",
    "    dataset[...] = new_data\n",
    "\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Open the HDF5 file in read mode\n",
    "with h5py.File('multilevel.h5', 'r') as hf:\n",
    "    # Accessing groups\n",
    "    print(\"Groups:\")\n",
    "    for group_name in hf:\n",
    "        print(f\"Group: {group_name}\")\n",
    "\n",
    "        # Accessing datasets within each group\n",
    "        group = hf[group_name]\n",
    "        print(f\"Datasets in {group_name}:\")\n",
    "        for dataset_name in group:\n",
    "            print(f\"Dataset: {dataset_name}\")\n",
    "\n",
    "            # Accessing data within datasets\n",
    "            dataset = group[dataset_name]\n",
    "            print(f\"Data in {dataset_name}: {dataset[:]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
